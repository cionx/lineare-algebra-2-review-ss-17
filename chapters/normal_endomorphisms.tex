\chapter{Normalenformen für normale Endomorphismen}

Es seien $V$ und $W$ endlichdimensionale Skalarprodukträume.

Für alle $\varphi \in \real$ sei
\[
            D(\varphi)
  \coloneqq \begin{pmatrix*}[r]
              \cos \varphi  & -\sin \varphi \\
              \sin \varphi  &  \cos \varphi
            \end{pmatrix*}
  \in       \matrices{2}{\Real}
\]
die Drehmatrix um den Winkel $\varphi$.





\section{Normale Endomorphismen}

Es sei $V$ ein endlichdimensionaler Skalarproduktraum und $f \colon V \to V$ ein Endomorphismus.

\begin{definition}
  \leavevmode
  \begin{itemize}
    \item
      Der Endomorphismus $f$ heißt \emph{normal} falls $f$ und $\adj{f}$ kommutieren, d.h.\ falls $f \circ \adj{f} = \adj{f} \circ f$ gilt.
    \item
      Eine Matrix $A \in \matrices{n}{\Korper}$ heißt normal, falls $A$ und $\madj{A}$ kommutieren, d.h.\ falls $A \madj{A} = \madj{A} A$ gilt.
  \end{itemize}
\end{definition}

\begin{lemma}
  Die folgenden Bedingungen sind äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist normal.
    \item
      Es gibt eine Orthonormalbasis $\basis{B}$ von $V$, so dass die Matrix $\repmatrixendo{f}{\basis{B}}$ normal ist.
    \item
      Für jede Orthonormalbasis $\basis{B}$ von $V$ ist die Matrix $\repmatrixendo{f}{\basis{B}}$ normal.
  \end{enumerate}
\end{lemma}



\subsection{Der komplexe Fall}

\begin{theorem}
  Für $\Korper = \Complex$ sind die folgenden Bedingungen sind äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist normal.
    \item
      Es gibt eine Orthonormalbasis von $V$ aus Eigenvektoren von $f$.
    \item
      Der Endomorphismus von $f$ ist diagonalisierbar und die Eigenräume sind orthogonal zueinander.
  \end{enumerate}
\end{theorem}

\begin{corollary}
  Für eine Matrix $A \in \matrices{n}{\Complex}$ sind die folgenden Bedingungen äquivalent:
  \begin{enumerate}
    \item
      Die Matrix $A$ ist normal.
    \item
      Es gibt eine Orthonormalbasis von $\Korper^n$ aus Eigenvektoren von $A$.
    \item
      Die Matrix $A$ ist diagonalisierbar und die Eigenräume sind orthogonal zueinander.
    \item
      Es gibt eine unitäre Matrix $U \in \Unitary{n}$, so dass $U^{-1} A U$ eine Diagonalmatrix ist.
  \end{enumerate}
\end{corollary}


Ist $A \in \matrices{n}{\Complex}$ eine normale Matrix, so lässt sich zum Berechnen einer Orthonormalbasis von $\Complex^n$ aus Eigenvektoren von $A$ wie folgt vorgehen:
\begin{itemize}
  \item
    Man berechne eine Basis $\basis{B}$ von $\Complex^n$ aus Eigenvektoren von $A$.
  \item
    Man wende für jeden Eigenwert von $A$ das Gram--Schidtsch-Verfahren auf die zugehörigen Basisvektoren aus $\basis{B}$ an.
\end{itemize}



\subsection{Der reelle Fall}

\begin{theorem}
  Für $\Korper = \Real$ sind die folgenden Bedingungen sind äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist normal.
    \item
      Es gibt eine Orthonormalbasis $\basis{B}$ von $V$, so dass $\repmatrixendo{f}{\basis{B}}$ von der Form
      \begin{equation}
      \label{equation: normal form for real normal endomorphisms}
          \repmatrixendo{f}{\basis{B}}
        = \begin{pmatrix}
            \lambda_1 &         &           &                   &         &                   \\
                      & \ddots  &           &                   &         &                   \\
                      &         & \lambda_t &                   &         &                   \\
                      &         &           & r_1 D(\varphi_1)  &         &                   \\
                      &         &           &                   & \ddots  &                   \\
                      &         &           &                   &         & r_s D(\varphi_s)
          \end{pmatrix}
      \end{equation}
      mit $\lambda_1, \dotsc, \lambda_t \in \Real$, $r_1, \dotsc, r_s > 0$ und $\varphi_1, \dotsc, \varphi_s \in (0, \pi)$ ist.
      Diese Form ist eindeutig bis auf Permutation der Diagonalblöcke.
  \end{enumerate}
\end{theorem}

\begin{remark}
  Das charakteristische Polynom der Drehstreckmatrix $r D(\varphi)$ ist $(t - \lambda)(t - \conjugate{\lambda}) = t^2 - 2\Re(\lambda) + \abs{\lambda}$ mit $\lambda = r e^{i \varphi}$.
  
  In \eqref{equation: normal form for real normal endomorphisms} entsprechen die reellen Diagonaleinträge also den reellen Nullstellen des charakteristischen Polynoms $\charpol{A}(t)$, und die Drehstreckmatrizen $r_i D(\varphi_i)$ den Paaren $(\lambda, \conjugate{\lambda})$ von rein komplexen Nullstelen von $\charpol{A}(t)$.
  
  Insbesondere lässt sich die Normalenform \eqref{equation: normal form for real normal endomorphisms} aus dem charakteristischen Polynom $\charpol{f}(t)$ ablesen, was die Eindeutig zeigt.
\end{remark}

\begin{example}
  Es sei $\Korper = \Real$ und $f$ normal mit charakteristischen Polynom
  \[
      \charpol{A}(t)
    = (t - 1)(t + 1)(t^2 + 1)(t^2 - 2t + 2).
  \]
  Es gilt $t^2 + 1 = (t - i)(t + i)$ mit $i = e^{i \pi/2}$ und $t^2 - 2t + 2 = (t - \lambda)(t - \conjugate{\lambda})$ mit $\lambda = 1 + i = \sqrt{2} e^{i \pi/4}$.
  Die zu $f$ gehörige Normalenform ist also
  \[
    \begin{pmatrix}
      1 &     &           &                   \\
        & -1  &           &                   \\
        &     & D(\pi/2)  &                   \\
        &     &           & \sqrt{2} D(\pi/4)
    \end{pmatrix}.
  \]
\end{example}

\begin{corollary}
  Für $A \in \matrices{n}{\Real}$ sind die folgenden Bedingungen äquivalent:
  \begin{enumerate}
    \item
      Die Matrix $A$ ist normal.
    \item
      Es gibt eine orthonormale Matrix $U \in \Orthogonal{n}$, so dass $U^{-1} A U$ in der Form \eqref{equation: normal form for real normal endomorphisms} ist, und es gilt die gleiche Eindeutigkeit.
  \end{enumerate}
\end{corollary}





\section{Unitäre \& Orthogonale Endomorphismen}

\begin{definition}
  Eine lineare Abbildung $f \colon V \to W$ heißt \emph{unitär} im Fall $\Korper = \Complex$, bzw.\ \emph{orthogonal} im Fall $\Korper = \Real$, falls
  \[
      \bil{f(v_1)}{f(v_2)}
    = \bil{v_1}{v_2}
    \qquad
    \text {für alle $v_1, v_2 \in V$}.
  \]
  gilt.
  Im Fall $\Korper = \Complex$ sei
  \begin{align*}
                \Unitary{V}
    &\coloneqq  \{ f \in \End{V} \suchthat \text{$f$ ist unitär} \}
  \intertext{und im Fall $\Korper = \Real$ sei}
                \Orthogonal{V}
    &\coloneqq  \{ f \in \End{V} \suchthat \text{$f$ ist orthogonal} \}
  \end{align*}
\end{definition}

\begin{lemma}
  \label{lemma: properties of unitary and orthogonal transformations}
  \begin{itemize}
    \item
      Unitäre und orthogonale Abbildungen sind injektiv.
    \item
      Es ist $\Unitary{V} \subseteq \GL{}{V}$, bzw.\ $\Orthogonal{V} \subseteq \GL{}{V}$ eine Untergruppe.
  \end{itemize}
\end{lemma}

Aus den Polarisationsformeln aus Abschnitt~\ref{section: quadratic forms and polarisation} für symmetrische Bilinearformen, bzw.\ Sesquilinearformen, erhält man die folgende Charakterisierung unitärer, bzw.\ orthogonaler Transformationen:

\begin{lemma}
  Eine lineare Abbildung $f \colon V \to W$ ist genau dann unitär, bzw.\ orthogonal, falls $f$ eine Isometrie ist, d.h.\ falls $\norm{ f(v) } = \norm{v}$ für alle $v \in V$ gilt.
\end{lemma}

Es sei nun $f \colon V \to V$ ein Endomorphismus.

\begin{lemma}
  Die folgenden Bedingungen sind äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist unitär, bzw.\ orthogonal.
    \item
      Der Endomorphismus $f$ ist ein Isomorphismus mit $f^{-1} = \adj{f}$.
    \item
      Es gilt $f \circ \adj{f} = \id_V$.
    \item
      Es gilt $\adj{f} \circ f = \id_V$.
  \end{enumerate}
\end{lemma}

\begin{lemma}
  Die folgenden Bedingungen äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist unitär, bzw.\ orthogonal.
    \item
      Es gibt eine Orthonormalbasis $\basis{B}$ von $V$, so dass $\repmatrixendo{f}{\basis{B}}$ unitär, bzw.\ orthogonal ist.
    \item
      Für jede Orthonormalbasis $\basis{B}$ von $V$ ist $\repmatrixendo{f}{\basis{B}}$ unitär, bzw.\ orthogonal.
  \end{enumerate}
\end{lemma}



\subsection{Der komplexe Fall}

\begin{theorem}
  Für $\Korper = \Complex$ sind die folgenden Bedingungen sind äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist unitär.
    \item
      Der Endomorphismus $f$ ist normal,und für jeden Eigenwert $\lambda \in \Complex$ von $f$ gilt $\abs{\lambda} = 1$.
  \end{enumerate}
\end{theorem}

\begin{corollary}
  Für eine Matrix $A \in \matrices{n}{\Complex}$ sind die folgenden Bedingungen äquivalent:
  \begin{enumerate}
    \item
      Die Matrix $A$ ist unitär.
    \item
      Die Matrix $A$ ist normal, und für jeden Eigenwert $\lambda \in \Complex$ von $A$ gilt $\abs{\lambda} = 1$.
  \end{enumerate}
\end{corollary}



\subsection{Der reelle Fall}

\begin{theorem}
  Für $\Korper = \Real$ sind die folgenden Bedingungen sind äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist orthogonal.
    \item
      Es gibt eine Orthonormalbasis $\basis{B}$ von $V$, so dass $\repmatrixendo{f}{\basis{B}}$ von der Form
      \begin{equation}
      \label{equation: normal form for orthogonal endomorphisms}
          \repmatrixendo{f}{\basis{B}}
        = \begin{pmatrix}
            \pm 1 &         &       &               &         &               \\
                  & \ddots  &       &               &         &               \\
                  &         & \pm 1 &               &         &               \\
                  &         &       & D(\varphi_1)  &         &               \\
                  &         &       &               & \ddots  &               \\
                  &         &       &               &         & D(\varphi_s)
          \end{pmatrix}
      \end{equation}
      mit $\varphi_1, \dotsc, \varphi_s \in (0, \pi)$ ist.
      Diese Form ist eindeutig bis auf Permutation der Diagonalblöcke.
      \textup(Insbesondere ist die Anzahl der Einsen und Minus-Einsen jeweils eindeutig bestimmt.\textup)
  \end{enumerate}
\end{theorem}

\begin{corollary}
  Für $A \in \matrices{n}{\Real}$ sind die folgenden Bedingungen äquivalent:
  \begin{enumerate}
    \item
      Die Matrix $A$ ist normal.
    \item
      Es gibt eine orthonormale Matrix $U \in \Orthogonal{n}$, so dass $U^{-1} A U$ in der Form \eqref{equation: normal form for orthogonal endomorphisms} ist, und es gilt die gleiche Eindeutigkeit.
  \end{enumerate}
\end{corollary}





\section{Selbstadjungierte Endomorphismen}

Es sei nun $f \colon V \to V$ ein Endomorphismus.

\begin{definition}
  Der Endomorphismus $f$ heißt \emph{selbstadjungiert}, falls $\adj{f} = f$ gilt.
\end{definition}

\begin{lemma}
  Die folgenden Bedingungen sind äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist selbstadjungiert.
    \item
      Es gibt eine Orthonormalbasis $\basis{B}$ von $V$, so dass die Matrix $\repmatrixendo{f}{\basis{B}}$ hermitesch ist.
    \item
      Für jede Orthonormalbasis $\basis{B}$ von $V$ ist die Matrix $\repmatrixendo{f}{\basis{B}}$ hermitesch.
  \end{enumerate}
\end{lemma}



\subsection{Normalenform}

\begin{theorem}
  Die folgenden Bedingungen sind äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist selbstadjungiert.
    \item
      Es gibt eine Orthonormalbasis von $V$ aus Eigenvektoren von $f$, und alle Eigenwerte von $f$ sind reell.
    \item
      Der Endomorphismus $f$ ist diagonalisierbar mit reellen Eigenwerten, und die Eigenräume sind orthogonal zueinander.
  \end{enumerate}
\end{theorem}

\begin{corollary}
  \label{corollary: hermitian matrices are diagonalizable}
  Für $A \in \matrices{n}{\Korper}$ sind die folgenden Bedingungen äquivalent:
  \begin{enumerate}
    \item
      Die Matrix $A$ ist hermitesch.
    \item
      Es gibt eine Orthonormalbasis von $\Korper^n$ aus Eigenvektoren von $A$, und alle Eigenwerte von $A$ sind reell.
    \item
      Die Matrix $A$ ist diagonalisierbar mit reellen Eigenwerten, und die Eigenräume sind orthogonal zueinander.
    \item
      Es gibt eine unitäre, bzw.\ orthogonale Matrix $U$, so dass $U^{-1} A U$ eine Diagonalmatrix mit reellen Diagonaleinträgen ist.
  \end{enumerate}
\end{corollary}

\begin{example}
  \leavevmode
  \begin{enumerate}
    \item
      Es sei
      \[
                  A
        \coloneqq \begin{pmatrix}
                    1 & 0 & 1 \\
                    0 & 1 & 1 \\
                    1 & 1 & 0
                  \end{pmatrix}
        \in       \matrices{3}{\Real}.
      \]
      Es gilt
      \[
          \charpol{A}(t)
        = - t^3 + 2 t^2 + t - 2
        = - (t-1)(t-2)(t+1),
      \]
      also sind $1$, $2$ und $-1$ die Eigenwerte von $A$.
      Die zugehörigen Eigenräume sind
      \begin{gather*}
          \eigenspace{(\Real^3)}{A}{1}
        = \ker  (A - \Id)
        = \ker  \begin{pmatrix*}[r]
                  0 & 0 &  1  \\
                  0 & 0 &  1  \\
                  1 & 1 & -1
                \end{pmatrix*}
        = \generated{ \rvect{1 \\ -1 \\ 0} },
      \\
          \eigenspace{(\Real^3)}{A}{2}
        = \ker  (A - 2\Id)
        = \ker  \begin{pmatrix*}[r]
                  -1  &  0  &  1 \\
                   0  & -1  &  1 \\
                   1  &  1  & -2
                \end{pmatrix*}
        = \generated{ \vect{1 \\ 1 \\ 1} },
      \\
          \eigenspace{(\Real^3)}{A}{-1}
        = \ker  (A + \Id)
        = \ker  \begin{pmatrix*}[r]
                  2 & 0 & 1 \\
                  0 & 2 & 1 \\
                  1 & 1 & 1
                \end{pmatrix*}
        = \generated{ \rvect{1 \\ 1 \\ -2} }.
      \end{gather*}
      Durch Normieren der obigen Eigenvektoren ergibt sich die Orthonormalbasis von $\Real^3$
      \[
          \basis{B}
        = \left(
            \frac{1}{\sqrt{2}} \rvect{1 \\ -1 \\ 0},
            \frac{1}{\sqrt{3}} \vect{1 \\ 1 \\ 1},
            \frac{1}{\sqrt{6}} \rvect{1 \\ 1 \\ -2}
          \right)
      \]
      bestehend aus Eigenvektoren von $A$.
      
    \item
      Es sei
      \[
                  A
        \coloneqq \begin{pmatrix*}[r]
                    -1  &  2  &  2 \\
                     2  & -1  &  2 \\
                     2  &  2  & -1
                  \end{pmatrix*}
        \in       \matrices{3}{\Real}
      \]
  \end{enumerate}
  Es gilt
  \[
      A + 3 \Id
    = \begin{pmatrix}
        2 & 2 & 2 \\
        2 & 2 & 2 \\
        2 & 2 & 2
      \end{pmatrix}
  \]
  und somit $\rank (A + 3 \Id) = 1$.
  Somit ist $\dim \ker (A + 3 \Id) = 2$.
  Also ist $-3$ ein Eigenwert von $A$ von Vielfachheit $2$.
  Der entsprechende Eigenraum ist
  \[
      \ker (A + 3 \Id)
    = \generated{ \rvect{1 \\ -1 \\ 0}, \rvect{0 \\ 1 \\ -1} }.
  \]
  
  Da $\tr A  =  -3$ gilt, ist $3$ der letzte übrige Eigenwert von $A$.
  Der entsprechende Eigenraum ist
  \[
      \ker (A - 3 \Id)
    = \ker \begin{pmatrix*}[r]
            -4  &  2  &  2  \\
             2  & -4  &  2  \\
             2  &  2  & -4
          \end{pmatrix*}
    = \generated{ \vect{1 \\ 1 \\ 1} }.
  \]
  Somit ist
  \[
              \basis{B}'
    \coloneqq \left(
                \rvect{1 \\ -1 \\ 0},
                \rvect{0 \\ 1 \\ -1},
                \vect{1 \\ 1 \\ 1}
              \right)
  \]
  eine Basis von $\Real^3$ aus Eigenvektoren von $A$.
  Durch
  \begin{itemize}
    \item
      Anwenden des Gram--Schmidt-Verfahrens auf die ersten beiden Basisvektoren, und
    \item
      Normieren des dritten Basisvektors
  \end{itemize}
  ergibt sich die Orthonormalbasis von $\Real^3$
  \[
    \basis{B}
    \coloneqq \left(
                \frac{1}{\sqrt{2}} \rvect{1 \\ -1 \\ 0},
                \frac{1}{\sqrt{6}} \rvect{1 \\ 1 \\ -2},
                \frac{1}{\sqrt{3}} \vect{1 \\ 1 \\ 1}
              \right)
  \]
  aus Eigenvektoren von $A$.
\end{example}



\subsection{Positive Endomorphismen \& Co.}

Selbstadjungierte Endomorphismen lassen sich als symmetrische Bilinearformen, bzw.\ hermitesche Sesquilinearform auffasen.

\begin{definition}
  \leavevmode
  \begin{itemize}
    \item
      Ein selbstadjungierter Endomorphismus $f \colon V \to V$ heißt \emph{positiv definit} falls die hermitesche Sesquilinearform $\beta \in \HerForm(V)$, bzw.\ die symmetrische Bilinearform $\beta \in \SymForm(V)$ mit $\beta(v_1, v_2) \coloneqq \bil{f(v_1)}{v_2}$ positiv definit ist.
    \item
      Eine hermitesche Matrix $A \in \matrices{n}{\Korper}$ heißt \emph{positiv definit} falls die hermitesche Sesquilinearform $\beta \in \HerForm(\Complex^n)$ mit $\beta(v_1, v_2) \coloneqq \transpose{v_1} A \conjugate{v_2}$ positiv definit ist.
  \end{itemize}
  
  Analog sind die Eigenschaften \emph{positiv semidefinit}, \emph{negativ definit}, \emph{negativ semidefinit} und \emph{indefinit} definiert.
\end{definition}

\begin{definition}
  Für einen selbstadjungierten Endomorphismus $f \colon V \to V$ sind die folgenden Bedingungen äquivalent:
  \begin{enumerate}
    \item
      Der Endomorphismus $f$ ist positiv definit.
    \item
      Es gibt eine Orthonormalbasis $\basis{B}$ von $V$, so dass die Matrix $\repmatrixendo{f}{\basis{B}}$ positiv definit ist.
    \item
      Für jede Orthonormalbasis $\basis{B}$ von $V$ ist die Matrix $\repmatrixendo{f}{\basis{B}}$ positiv definit.
  \end{enumerate}
  Für positiv semidefinit, negativ definit, negativ semidefinit und indefinit definiert gelten die analogen Aussagen.
\end{definition}

\begin{corollary}
  \leavevmode
  \begin{itemize}
    \item
      Ein selbstadjungierter Endomorphismus $f \colon V \to V$ ist genau dann positiv definit, wenn alle Eigenwerte von $f$ positiv sind.
    \item
      Eine hermitesche Matrix $A \in \matrices{n}{\Korper}$ ist genau dann positiv definit, wenn alle Eigenwerte von $A$ positiv sind.
  \end{itemize}
  Für positiv semidefinit, negativ definit, negativ semidefinit und indefinit definiert gelten die analogen Aussagen.
\end{corollary}





\section{Übersicht}

Die verschiedenen Normalenformen lassen sich wie folgt zusammenfassen:

\begin{center}
  \tabcolsep=0pt
  \begin{tabular}[4]{lccc}
      {}
    & \begin{tabular}[1]{c}
        Charakterisierung \\
        durch $\adj{f}$
      \end{tabular}
    & $\Korper = \Complex$
    & $\Korper = \Real$
    \\
    \hline
    \hline
    \\
      normal
    & $f \adj{f} = \adj{f} f$
    & \begingroup
        \renewcommand*{\arraystretch}{1.5}
        \begin{tabular}[1]{@{}c}
        
        $ \begin{psmallmatrix}
            \lambda_1 &         &           \\
                      & \ddots  &           \\
                      &         & \lambda_n
          \end{psmallmatrix}$
        \\
        $\lambda_i \in \Complex$
        \end{tabular}
      \endgroup
    & \begingroup
        \renewcommand*{\arraystretch}{1.5}
        \begin{tabular}[1]{@{}c}
          $ \begin{psmallmatrix}
              \lambda_1 &         &           &                   &         &                   \\
                        & \ddots  &           &                   &         &                   \\
                        &         & \lambda_t &                   &         &                   \\
                        &         &           & r_1 D(\varphi_1)  &         &                   \\
                        &         &           &                   & \ddots  &                   \\
                        &         &           &                   &         & r_s D(\varphi_s)
            \end{psmallmatrix} $
        \\
        $\lambda_i \in \Real$, $r_i > 0$,  $\varphi_i \in (0, \pi)$
        \end{tabular}
      \endgroup
    \\
    \hline
    \\
      unitär,
      orthogonal
    & $\adj{f} = f^{-1}$
    & \begingroup
        \renewcommand*{\arraystretch}{1.5}
        \begin{tabular}[1]{@{}c}
        
        $ \begin{psmallmatrix}
            \lambda_1 &         &           \\
                      & \ddots  &           \\
                      &         & \lambda_n
          \end{psmallmatrix}$
        \\
        $\abs{\lambda_i} = 1$
        \end{tabular}
      \endgroup
    & \begingroup
        \renewcommand*{\arraystretch}{1.5}
        \begin{tabular}[1]{@{}c}
          $ \begin{psmallmatrix}
              \pm 1 &         &       &               &         &               \\
                    & \ddots  &       &               &         &               \\
                    &         & \pm 1 &               &         &               \\
                    &         &       & D(\varphi_1)  &         &               \\
                    &         &       &               & \ddots  &               \\
                    &         &       &               &         & D(\varphi_s)
            \end{psmallmatrix} $
        \\
        $\varphi_i \in (0, \pi)$
        \end{tabular}
      \endgroup
    \\
    \hline
    \\
      selbstadjungiert
    & $\adj{f} = f$
    & \multicolumn{2}{@{}c}
      {
       \begingroup
        \renewcommand*{\arraystretch}{1.5}
        \begin{tabular}[1]{@{}c}
        
        $ \begin{pmatrix}
            \lambda_1 &         &           \\
                      & \ddots  &           \\
                      &         & \lambda_n
          \end{pmatrix}$
        \\
        $\lambda_i \in \Real$
        \end{tabular}
        \endgroup
      }
  \end{tabular}
\end{center}





\section{Polarzerlegung}

\begin{lemma}
  \label{lemma: existence of square roots}
  \leavevmode
  \begin{itemize}
    \item
      Für jeden positiv semidefiniten selbstadjungierten Endomorphismus $f \colon V \to V$ gibt es einen eindeutigen positiv semidefinitinen selbstadjungierten Endomorphismus $g \colon V \to V$ mit $f = g^2$.
    \item
      Für jede positiv semidefinite hermitesche Matrix $A \in \matrices{n}{\Korper}$ gibt es eine eindeutige positiv semidefinite hermitesche Matrix $B \in \matrices{n}{\Korper}$ mit $A = B^2$.
  \end{itemize}
\end{lemma}

In der Situation von Lemma~\ref{lemma: existence of square roots} schreiben wir $g = \sqrt{f}$ (bzw.\ $B = \sqrt{A}$).

\begin{theorem}[Polarzerlegung]
  \leavevmode
  \begin{itemize}
    \item
      Für jeden Endomorphismus $f \colon V \to V$ gibt es einen selbstadjungierten Endomorphismus $s \colon V \to V$ und einen unitären, bzw.\ orthogonalen Endomorphismus $u \colon V \to V$ mit $f = s \circ u$.
      Der Endomorphismus $s$ ist eindeutig bestimmt durch $s = \sqrt{f \circ \adj{f}}$.
      Ist $f$ invertierbar, so ist auch $u$ eindeutig.
    
    \item
      Für jede Matrix $A \in \matrices{n}{\Korper}$ gibt eine hermitesche Matrix $S \in \matrices{n}{\Korper}$ und eine unitäre, bzw.\ orthogonale Matrix $U \in \matrices{n}{\Korper}$ mit $A = SU$.
      Die Matrix $S$ ist eindeutig bestimmt durch $S = \sqrt{A \madj{A}}$.
      Ist $A$ invertierbar, so ist auch $U$ eindeutig.
  \end{itemize}
\end{theorem}




